{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81014140-e3d4-4297-9244-86a313e151b9",
   "metadata": {},
   "source": [
    "# MAC0318 Introdução à Programação de Robôs Móveis\n",
    "\n",
    "## Planejamento de rotas\n",
    "\n",
    "Nessa atividade, vamos usar técnicas de busca heurística em grafo para resolver o problema de encontra uma rota ótima. Um problema de planejamento é definido matematicamente por:\n",
    "- Um conjunto de estados $S$\n",
    "- Um estado inicial $s_0 \\in S$\n",
    "- Um estado meta $s_m \\in S$\n",
    "- Um conjunto de ações $A$\n",
    "- Uma função $A: S \\rightarrow 2^A$, que associa a cada estado um conjunto de ações aplicáveis $A(s)$ em um estado $s$\n",
    "- Uma função de transição $T: S \\times A \\rightarrow S$, que representa a transição de estado $T(s,a)$ causada por uma ação $a$ a partir de um estado $s$\n",
    "- Uma função de custo $C: S \\times A \\rightarrow \\mathbb{R}$, que associa um custo a uma transição.\n",
    "\n",
    "Note que o custo pode ser negativo, de fato representando uma recompensa. O objetivo do problema é encontrar uma sequência de ações aplicáveis $a_1, a_2, \\ldots, a_H$ tal que levem do estado inicial ao estado meta como mínimo custo. A sequência de ações produz uma trajetória\n",
    "$$\n",
    "  s_1 = T(s_0, a_1), \\, s_2 = T(s_1, a_2), \\, \\ldots, \\, s_H = T(s_{H-1}, a_H) ,\n",
    "$$\n",
    "para a qual $a_t \\in A(s_{t-1})$ para todo $t=1,\\ldots,H$. Por definição, uma solução para o problema requer que $H$ seja finito, que $s_H = s_m$ e que\n",
    "$$\n",
    "  C(s_0, a_1) + C(s_1, a_2) + \\dotsb + C(s_{H-1}, a_H)\n",
    "$$\n",
    "seja minímo sobre todas as sequências de ações aplicáveis que levem ao estado meta.\n",
    "\n",
    "Equivalentemente, o problema pode ser formulado como encontrar o caminho mais curto em um multigrafo $G$ com vértices $V$, arestas $A$ e pesos $C: A \\rightarrow \\mathbb{R}$ sobre as aretas. Note que em um multigrafo pode haver mais de uma aresta entre dois nós, portanto $A$ é um [multiconjunto](https://pt.wikipedia.org/wiki/Multiconjunto). Note no entanto que em problemas de planejamento o espaco de estados e ações é em geral muito grande ou mesmo infinito, e o grafo subjacente é representado apenas implicitamente por meio da função de transição.\n",
    "\n",
    "## Grade de ocupação\n",
    "\n",
    "\n",
    "Vamos usar como domínio um mapa representado como **grade de ocupação**, isto é, uma matriz de 0s e 1s com 0 indicando uma célula ocupável (ou seja, que o agente pode ocupar) e 1 indicando uma célula ocupada (ou seja, que o agente _não_ pode ocupar). Vamos assumir uma 4-vizinhança: o agente pode se deslocar para a células ocupáveis acima, à direita, à esquerda e abaixo, como mostra a figura abaixo.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "    <img src=\"img/four-neighborhood.png\" width=\"300\">\n",
    "</figure>\n",
    "\n",
    "O ambiente será portanto representado como um grafo planar no qual os nós representam células e as aretas representam ações de locomoção. Vamos gerar um mundo aleatório assumindo que cada célula é ocupada independentemente com uma dada probabilidade. Vamos assumir que o agente inicia sempre na célula central em $(\\lfloor largura/2 \\rfloor, \\lfloor altura/2 \\rfloor)$, e que portanto é sempre desocupada. Os custos de todas as ações serão unitários.\n",
    "\n",
    "O problema de planejamento de rota nesse mundo é encontrar um caminho do nó incial a um nó meta desejado com o menor comprimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8ade45-31d9-4391-b8dd-5a1adcfbc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe as bibliotecas necessárias\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d08ab45-14e5-4e22-956e-3cc1a070e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir uma estrutura de dados para representar um estado (uma célula)\n",
    "@dataclass(frozen = True)\n",
    "class State:\n",
    "    x: int\n",
    "    y: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7363fbf4-e080-4d3f-8951-c7f65cd0aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classe abaixo representa o problema de planejamento no mundo de grade de ocupação\n",
    "class World:\n",
    "    width: int\n",
    "    height: int\n",
    "    density: float\n",
    "    grid: np.ndarray\n",
    "    initial_state: State\n",
    "    \n",
    "    def __init__(self, width: int, height: int, density: float, message=True):\n",
    "        self.grid = np.random.rand(height, width) < density\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.initial_state = State(width//2, height//2)\n",
    "        self.grid[height//2,width//2] = False\n",
    "        if message:\n",
    "            print(\"World has\", self.grid.size-self.grid.sum(), \"occupable cells.\")\n",
    "        \n",
    "    def actions(self, state: State):\n",
    "        ''' Returns applicable actions at given `state`. '''\n",
    "        valid_actions = []\n",
    "        if state.x > 0 and not self.grid[state.y,state.x-1]:\n",
    "            valid_actions.append(\"left\")\n",
    "        if state.x < self.width - 1 and not self.grid[state.y,state.x+1]:\n",
    "            valid_actions.append(\"right\")\n",
    "        if state.y > 0 and not self.grid[state.y-1,state.x]:\n",
    "            valid_actions.append(\"up\")\n",
    "        if state.y < self.height - 1 and not self.grid[state.y+1,state.x]:\n",
    "            valid_actions.append(\"down\")\n",
    "        return valid_actions\n",
    "    \n",
    "    def next_state(self, state: State, action: str):\n",
    "        ''' Returns the successor state when applying the given `action` in given `state`. \n",
    "            Assumes `action` is applicable at `state`. '''\n",
    "        if action == \"left\":\n",
    "            return State(state.x-1, state.y)\n",
    "        elif action == \"right\":\n",
    "            return State(state.x+1, state.y)\n",
    "        elif action == \"up\":\n",
    "            return State(state.x, state.y-1)\n",
    "        elif action == \"down\":\n",
    "            return State(state.x, state.y+1)\n",
    "        \n",
    "    def cost(self, state: State, action: str):\n",
    "        ''' Returns cost of taking `action` in given `state`. '''\n",
    "        return 1.0\n",
    "        \n",
    "    def show(self, plan=None):\n",
    "        ''' Shows world and initial state. If plan is given, also displays trajectory. '''\n",
    "        M = 1-self.grid.astype(np.float32)\n",
    "        M[self.initial_state.y,self.initial_state.x] = 0.5\n",
    "        if plan is not None:\n",
    "            for state in plan:\n",
    "                M[state.y,state.x] = 0.5\n",
    "        plt.imshow(M, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02c89b67-e286-4445-be13-cc54b563e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World has 610 occupable cells.\n"
     ]
    }
   ],
   "source": [
    "# Criamos um mundo aleatório com as dimensões dadas (largura, altura, densidade de ocupação)\n",
    "world = World(40,20,0.25) # quanto maior a densidade, menor a probabilidade de solução (caminho de início à meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43672a6a-5859-40b8-b5d6-c3ef332d559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizamos o mundo obtido -- células pretas são ocupadas, brancas são livres, cinza marca posição inicial\n",
    "world.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25b29946-30dc-4ebf-8e98-c7c0f4116b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(x=20, y=10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estado inicial\n",
    "world.initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15f3cd79-b0a7-4afb-a5e3-9410494fd735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left', 'right', 'up', 'down']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ações aplicáveis no estado inicial\n",
    "world.actions(world.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38ca4fe9-2973-4794-b6d9-7f6b5f5376fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right', 'down']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ações aplicáveis no estado (x=0, y=0)\n",
    "world.actions(State(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9b104ed-0170-4831-bb57-2231a644b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(x=21, y=10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transição do estado inicial aplicando ação \"ir para a direita\"\n",
    "world.next_state(world.initial_state, \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fe27fa6-a4cf-4dc9-80f1-59b4f9a8cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custo da ação\n",
    "world.cost(world.initial_state, \"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d78130-278e-4146-b9c8-7f57d5719b84",
   "metadata": {},
   "source": [
    "## Busca em profundidade\n",
    "\n",
    "A busca em profundidade consiste em explorar um caminho até que não haja mais ações aplicáveis, e então retornar ao estado anterior. Ela é implementada mantendo-se uma pilha de estados como fronteira e selectionando sempre um estado de maior altura na fronteira (distância do camimho do mais curto ao estado inicial). A busca é subótima, sem garantias na qualidade da solução encontrada. Memorizar os estados visitados torna a busca completa, evitando ciclos de visitas. Com memorização, o uso de memória é proporcional ao comprimento do caminho explorado, que é limitado superiormente pelo tamanho do maior caminho à meta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0856bf-7345-45c9-9608-fb98851c799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca em profundidade com memória\n",
    "def depth_first_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = [world.initial_state]       # candidate states to be visited\n",
    "    path_cost = {world.initial_state: 0.0} # path cost from initial state to each visited state\n",
    "    visited = set() # visited states - avoids cycles\n",
    "    backtrack = {}  # backtrack generator state to obtain solution (path)\n",
    "    num_visited_states = 0 # for statistics\n",
    "    while frontier:\n",
    "        state = frontier.pop()\n",
    "        visited.add(state)\n",
    "        num_visited_states += 1 # for producing statistics only\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = [] # a deterministic plan is a sequence of actions taking the agent from the initial state to the goal state\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        # Otherwise, expand frontier with non-visited neighbors\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            if next_state not in visited: # Avoids cycles\n",
    "                path_cost[next_state] = path_cost[state] + world.cost(state, action) # partial path cost (not really necessary here)\n",
    "                frontier.append(next_state)   # add state to frontier\n",
    "                backtrack[next_state] = state # remeber transition\n",
    "    # search failed - there is no solution\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63e6aff7-cb87-4d23-afdf-de752fa02736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 152.0 visiting 770 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = depth_first_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b595e0fb-bd58-452f-9ea3-8512bce75aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb627ad-eb61-4fda-959b-fe106a72b836",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Antes de prosseguir, procure se familiarizar com o algoritmo da busca em profundidade. Rode o algoritmo com mundos diferentes, obtidos alterando a densidade de células ocupadas (use valores como 0.1 e 0.5). Use metas atingíveis e inatingíveis e veja os resultados, notando o número de estados visitados. Com o mundo fixo, procure encontrar o estado meta que leva ao pior caso para a busca em número de estados visitados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482abf99-a3af-466d-8fc2-5be368024c55",
   "metadata": {},
   "source": [
    "## Busca em largura\n",
    "\n",
    "A busca em largura visita todos os nós a uma certa altura antes dos estados de altura estritamente maior. Ela é implementada mantendo-se uma fila de estados como fronteira e selecionando um nó de mínima altura na fronteira. A busca é subótima, sem garantia de qualidade da solução encontrada. A busca não requer memorização de estados para ser completa, mas a memorização reduz a memória utilizada, tornando a busca mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8884b5a6-7c60-48e0-a347-1f9e8e99fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca em largura com memória\n",
    "def breadth_first_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = deque([world.initial_state])\n",
    "    path_cost = {world.initial_state: 0.0}\n",
    "    visited = set()\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    while frontier:\n",
    "        state = frontier.popleft()\n",
    "        visited.add(state)\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            if next_state not in visited: # Avoids cycles\n",
    "                path_cost[next_state] = path_cost[state] + world.cost(state, action)\n",
    "                frontier.append(next_state)\n",
    "                backtrack[next_state] = state\n",
    "    # search failed - no solution\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85dc0360-4976-4909-9d8f-cf0946fda90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 34.0 visiting 122332 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = breadth_first_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7608085-d6c1-4f54-bf4c-2c83f505ff04",
   "metadata": {},
   "source": [
    "Note que como a função de custo em nosso domínio é uniforme (constante), a busca em largura encontra uma solução ótima (ou seja, de menor custo total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c832c568-e95c-4e41-a2e0-179d0de2f614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADGCAYAAADc30sqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASZklEQVR4nO3dfawc1XnH8e+vBqc1WBiC5WCwCUkRFULBsW+doFJkQkPBQnFSUWLUF9IQGRBIQSpqCZW4diSkphWhL44gJDhARXhpEhNLsQArQQKkBLh2DZi34LhG2Di2gfBW0iLD0z92btisd+8uO7OzZ49/H+nqzs7M7nn27Oxz586es48iAjMzy9fvDDsAMzMbLCd6M7PMOdGbmWXOid7MLHNO9GZmmTto2AG0M2PGjJg1a1bH7XPnzi3dxsaNG6fcvmjRotJtjIpufVGXbn1eR5x1xFDFsVXF8ev3wHvq6ItBt7F9+3ZeeukltdumMsMrJZ0F/CswDfh2RPxjy/YPALcCi4CXgc9HxPZujzt37ty46KKLOm4fHx/vO+am2KbcfiANO+3WF3Xp1ud1xFlHDFUcW1Ucv34PvKeOvhh0G2NjY0xMTLRtpO9LN5KmAd8AzgZOBM6XdGLLbhcCv4qI3weuA77Wb3tmZtafMtfoFwNbI2JbRLwN3AEsa9lnGXBLsfw94AylcvpoZnaAKJPojwZeaLq9o1jXdp+I2Ae8BnywRJtmZvY+JTPqRtIKSROSJt56661hh2Nmlo0yiX4nMK/p9jHFurb7SDoIOIzGh7L7iYgbI2IsIsZmzJhRIiwzM2tWJtE/Chwv6ThJ04HlwLqWfdYBFxTL5wI/iQPpo3wzswT0PY4+IvZJugy4l8bwyjUR8aSkrwITEbEOuAn4D0lbgVdo/DGoRQ7DpVKRyvOoI45Uhk/W0UYqr+ug9fKajspr1q9SE6YiYj2wvmXd1U3L/wv8eZk2zMysnGQ+jDUzs8Fwojczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZS7JwiPdjMoEiDrirGOCTxXPI5XXrKw6JtpV0U5dr1lZdXxvfh1t1PWlvP0eFz6jNzPLnBO9mVnmnOjNzDLnRG9mlrkyNWPnSbpf0lOSnpT05Tb7LJH0mqTNxc/V7R7LzMwGp8yom33A30bEJkkzgY2SNkTEUy37PRgR55Rox8zMSuj7jD4idkXEpmL5DeBp9q8Za2ZmQ1bJOHpJHwY+DjzcZvMpkh4DXgSuiIgny7a3cuXKrvusWrWqbDNdjY+PT7m9rjHX3ZSNI5Xx7XUUeklh/kUqbdRx/NY1/nzQUnmPdFI60Us6FPg+cHlEvN6yeRNwbES8KWkpcDdwfIfHWQGsADjssMPKhmVmZoVSo24kHUwjyd8WET9o3R4Rr0fEm8XyeuBgSUe2eywXBzczG4wyo25Eoybs0xHx9Q77fKjYD0mLi/Ze7rdNMzN7/8pcuvkj4K+AJyRtLtZdBcwHiIgbgHOBSyTtA34NLI/UL2aZmWWm70QfEQ8BU36SEhGrgdX9tmFmZuV5ZqyZWeac6M3MMudEb2aWuSQLj8ydO3fKyUh1TCLqZcJVChN4eumLOuLsJpUJPNa7Ko6bOl6zFOJMvbCOz+jNzDLnRG9mljknejOzzDnRm5llzonezCxzTvRmZplzojczy1yS4+i76WU8ah0FDXopgDJodfRFXcVP6hjvX7aN1MdLVymX51HH8Zt6X5U+o5e0XdITRfHviTbbJenfJG2V9LikhWXbNDOz3lV1Rn96RLzUYdvZNKpKHQ98Ari++G1mZjWo4xr9MuDWaPgZMEvSUTW0a2ZmVJPoA7hP0sai7muro4EXmm7vKNb9FkkrJE1Imti7d28FYZmZGVST6E+NiIU0LtFcKum0fh6kuWbs7NmzKwjLzMyggkQfETuL33uAtcDill12AvOabh9TrDMzsxqUSvSSDpE0c3IZOBPY0rLbOuCvi9E3nwRei4hdZdo1M7PelR11MwdYW4xTPQj4bkTcI+li+E2B8PXAUmAr8BbwNyXbrGUs81Tfhz+pl++sz0FdY4RTGItcxVj+FL7/PxV1zcEY5P1zUCrRR8Q24OQ2629oWg7g0jLtmJlZ//wVCGZmmXOiNzPLnBO9mVnmnOjNzDLnRG9mljknejOzzDnRm5llLtvCIymoY2JXLm300k4VbYxKXxwoUikiVFbqx4XP6M3MMudEb2aWOSd6M7PMOdGbmWWu70Qv6YSiIPjkz+uSLm/ZZ4mk15r2ubp0xGZm9r70PeomIp4FFgBImkajmMjaNrs+GBHn9NuOmZmVU9WlmzOAX0TE8xU9npmZVaSqcfTLgds7bDtF0mPAi8AVEfFku52KwuIrmm6XCiiFscwrV67sus8oFKmoY4x8Ve0MWl3jvru1U0eBlG5G5bioo43UC9KUPqOXNB34DPCfbTZvAo6NiJOBfwfu7vQ4zcXBy8ZkZmbvqeLSzdnApojY3bohIl6PiDeL5fXAwZKOrKBNMzPrURWJ/nw6XLaR9CEV/69IWly093IFbZqZWY9KXaOXdAjwaeCipnXNhcHPBS6RtA/4NbA8RuFCrJlZRsoWB/8f4IMt65oLg68GVpdpw8zMyvHMWDOzzDnRm5llzonezCxzSRYeWbRoERMTE8MOo6vx8fEpt69atarrY9QxMSYFqU8oqVIucdYx8asXozCxq5c2XHjEzMwGxonezCxzTvRmZplzojczy5wTvZlZ5pzozcwy50RvZpa5JMfRd5NLEQsoPz63ir7oZbx/HboVaukWZy+FXrqpoq+6za+o4jWr4/gelfeQ+6K7ns7oJa2RtEfSlqZ1R0jaIOm54vfhHe57QbHPc5IuqCpwMzPrTa+Xbm4GzmpZdyXw44g4Hvhxcfu3SDoCGAc+ASwGxjv9QTAzs8HoKdFHxAPAKy2rlwG3FMu3AJ9tc9c/BTZExCsR8StgA/v/wTAzswEq82HsnIjYVSz/EpjTZp+jgReabu8o1u1H0gpJE5Im9u7dWyIsMzNrVsmom6JqVKlPK5qLg8+ePbuKsMzMjHKJfrekowCK33va7LMTmNd0+5hinZmZ1aRMol8HTI6iuQD4YZt97gXOlHR48SHsmcU6MzOriXr8nvDbgSXAkcBuGiNp7gbuAuYDzwPnRcQrksaAiyPiS8V9vwhcVTzUNRHxnW7tjY2NxVTfR1/FOOQ6vms7lfHpZfUyPr2Occaj0p/dxtFbekalFkIPcbbdoacJUxFxfodNZ7TZdwL4UtPtNcCaXtoxM7Pq+SsQzMwy50RvZpY5J3ozs8w50ZuZZc6J3swsc070ZmaZc6I3M8tcTxOm6tZtwlQdXNwkvTasWn7NepfCe6hbO2NjY0xMTLR9EJ/Rm5llzonezCxzTvRmZplzojczy1zXRN+hMPg/S3pG0uOS1kqa1eG+2yU9IWmzpOF+umpmdoDq5Yz+Zvav87oBOCkiPgb8HPjKFPc/PSIWRMRYfyGamVkZXRN9u8LgEXFfROwrbv6MRuUoMzNLUE/fR9/FF4E7O2wL4D5JAXwzIm7s9CCSVgArAObPnz9lg1UUDemmx4IspR8jFyk81zrmPtQ1v6LsMZ7C69GLOooIVdEXVRQy6vYYVeScTkp9GCvpH4B9wG0ddjk1IhYCZwOXSjqt02O5OLiZ2WD0neglfQE4B/iL6PCnKCJ2Fr/3AGuBxf22Z2Zm/ekr0Us6C/g74DMR8VaHfQ6RNHNymUZh8C3t9jUzs8HpZXjl7cBPgRMk7ZB0IbAamAlsKIZO3lDsO1fS+uKuc4CHJD0GPAL8KCLuGcizMDOzjrp+GNuhMPhNHfZ9EVhaLG8DTi4VnZmZleaZsWZmmXOiNzPLnBO9mVnmqpgwVbsUJqT0EkcuxUtSeR51TJSrQhUTeKo4tsq2MSpSeB51TbDsVnikE5/Rm5llzonezCxzTvRmZplzojczy5wTvZlZ5pzozcwy50RvZpa5kRxHX4U6xt6mML63CqkUYaljbHnZGCw9qcwDGaZ+i4OvlLSz+ObKzZKWdrjvWZKelbRV0pVVBm5mZr3ptzg4wHVF0e8FEbG+daOkacA3aFSXOhE4X9KJZYI1M7P3r6/i4D1aDGyNiG0R8TZwB7Csj8cxM7MSynwYe5mkx4tLO4e32X408ELT7R3FurYkrZA0IWli7969JcIyM7Nm/Sb664GPAguAXcC1ZQNxcXAzs8HoK9FHxO6IeCci3gW+Rfui3zuBeU23jynWmZlZjfotDn5U083P0b7o96PA8ZKOkzQdWA6s66c9MzPrX9dx9EVx8CXAkZJ2AOPAEkkLgAC2AxcV+84Fvh0RSyNin6TLgHuBacCaiHhyEE9iEOoae1t2/HlOY4TL9sWoPM8qHEjPtawU3qdVxdGvgRUHL26vB/YbemlmZvXxVyCYmWXOid7MLHNO9GZmmXOiNzPLnBO9mVnmnOjNzDLnRG9mlrkDtvBIN1UU26iqnUHevxdVTMqq4zHqeM1SKcKSi1QmM9VRtGaYfEZvZpY5J3ozs8w50ZuZZc6J3swsc718e+Ua4BxgT0ScVKy7Ezih2GUW8GpELGhz3+3AG8A7wL6IGKskajMz61kvo25uBlYDt06uiIjPTy5LuhZ4bYr7nx4RL/UboJmZldPL1xQ/IOnD7bapMSbpPOBTFcdlZmYVKTuO/o+B3RHxXIftAdwnKYBvRsSNnR5I0gpgBcD8+fNLhlWPURkPnUJBj1F5jBTmRqSijvHpqcxLSGU+Sjf9xln2w9jzgdun2H5qRCwEzgYulXRapx1dHNzMbDD6TvSSDgL+DLiz0z4RsbP4vQdYS/si4mZmNkBlzuj/BHgmIna02yjpEEkzJ5eBM2lfRNzMzAaoa6IvioP/FDhB0g5JFxabltNy2UbSXEmTNWLnAA9Jegx4BPhRRNxTXehmZtaLfouDExFfaLPuN8XBI2IbcHLJ+MzMrCTPjDUzy5wTvZlZ5pzozcwy58IjHYzKxJkqCnrUYVTirKOASi9GoXjJqBTrGJX38iDb8Bm9mVnmnOjNzDLnRG9mljknejOzzDnRm5llzonezCxzTvRmZplTCuNxW0naCzzftOpIYBTKEY5CnKMQIzjOqjnOaqUY57ER0baYR5KJvpWkiVEoLD4KcY5CjOA4q+Y4qzUqcU7ypRszs8w50ZuZZW5UEn3HouKJGYU4RyFGcJxVc5zVGpU4gRG5Rm9mZv0blTN6MzPrkxO9mVnmkk70ks6S9KykrZKuHHY8nUjaLukJSZslTQw7nkmS1kjaI2lL07ojJG2Q9Fzx+/BhxljE1C7OlZJ2Fn26WdLSYcZYxDRP0v2SnpL0pKQvF+uT6dMpYkyqPyX9rqRHJD1WxLmqWH+cpIeL9/ydkqYnGufNkv67qT8XDDPOriIiyR9gGvAL4CPAdOAx4MRhx9Uh1u3AkcOOo01cpwELgS1N6/4JuLJYvhL4WqJxrgSuGHZsLXEeBSwslmcCPwdOTKlPp4gxqf4EBBxaLB8MPAx8ErgLWF6svwG4JNE4bwbOHXY/9vqT8hn9YmBrRGyLiLeBO4BlQ45ppETEA8ArLauXAbcUy7cAn60zpnY6xJmciNgVEZuK5TeAp4GjSahPp4gxKdHwZnHz4OIngE8B3yvWD/34nCLOkZJyoj8aeKHp9g4SPGALAdwnaaOkFcMOpos5EbGrWP4lMGeYwXRxmaTHi0s7Q7/E1EzSh4GP0zjDS7JPW2KExPpT0jRJm4E9wAYa/8G/GhH7il2SeM+3xhkRk/15TdGf10n6wPAi7C7lRD9KTo2IhcDZwKWSTht2QL2Ixv+jqZ6dXA98FFgA7AKuHWo0TSQdCnwfuDwiXm/elkqftokxuf6MiHciYgFwDI3/4P9guBG11xqnpJOAr9CI9w+BI4C/H16E3aWc6HcC85puH1OsS05E7Cx+7wHW0jhoU7Vb0lEAxe89Q46nrYjYXbzB3gW+RSJ9KulgGgn0toj4QbE6qT5tF2Oq/QkQEa8C9wOnALMkHVRsSuo93xTnWcUlsoiI/wO+Q0L92U7Kif5R4PjiU/jpwHJg3ZBj2o+kQyTNnFwGzgS2TH2voVoHXFAsXwD8cIixdDSZOAufI4E+lSTgJuDpiPh606Zk+rRTjKn1p6TZkmYVy78HfJrG5wn3A+cWuw39+OwQ5zNNf9hF43OEoR+fU0l6ZmwxBOxfaIzAWRMR1ww3ov1J+giNs3iAg4DvphKnpNuBJTS+UnU3MA7cTWNkw3waXwV9XkQM9YPQDnEuoXGZIWiMarqo6Tr4UEg6FXgQeAJ4t1h9FY1r4En06RQxnk9C/SnpYzQ+bJ1G44Tzroj4avF+uoPG5ZD/Av6yOGtOLc6fALNpjMrZDFzc9KFtcpJO9GZmVl7Kl27MzKwCTvRmZplzojczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8z9P94gNX220A9qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5ff3b-3186-4ca4-9acf-42f41b5fa85e",
   "metadata": {},
   "source": [
    "## Busca em largura com memorização da fronteira\n",
    "\n",
    "Podemos tornar a busca em largura mais eficiente evitando duplicar estados na fronteira. Como a busca em largura explora os estados em \"curvas de níveis\" de altura constante, os estados são adicionados à fronteira através de caminhos de mesmo comprimento. A implementação a seguir substitui a memorização de estados visitados pela memorização de estados gerados (isto é, inseridos na fronteira), aproveitando o dicionário `path_cost` já existente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "869ed1be-3f23-41cb-bc16-9f9e6b0e6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca em largura com memória\n",
    "def breadth_first_search2(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = deque([world.initial_state])\n",
    "    path_cost = {world.initial_state: 0.0} # computes partial costs and remebers generated states\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    while frontier:\n",
    "        state = frontier.popleft()\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            if next_state not in path_cost: # States are inserted at frontier only once - reduces memory footprint\n",
    "                path_cost[next_state] = path_cost[state] + world.cost(state, action)\n",
    "                frontier.append(next_state)\n",
    "                backtrack[next_state] = state\n",
    "    # failed search\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b70ba72e-33a6-4f8f-bcaa-1652977aa616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 34.0 visiting 601 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = breadth_first_search2(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eeef7f-7375-4d22-88e7-0c4c14b984f6",
   "metadata": {},
   "source": [
    "Note como a busca encontra uma solução ótima (para o caso de custo uniforme) com uma quantidade de estados visitados muito menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42853d4d-9780-4b1b-9f7f-982eeed561be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80322f6d-aef2-4bbc-b46c-240c8267c793",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Procure se familiarizar com o algoritmo da busca em largura. Rode o algoritmo com mundos diferentes, com metas atingíveis e inatingíveis e veja os resultados. Compare os custos e número de nós visitados entre as buscas em largura e em profundidade para um mesmo problema. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f21ab1-6c9b-44f9-b1f4-bfb25501991d",
   "metadata": {},
   "source": [
    "## Busca informanda\n",
    "\n",
    "A busca A* visita os nós seguindo uma função combinada entre o custo e uma heurística admissível, que subestima o custo restante de uma estado à meta. A busca não requer memorização de estados para ser completa ou ótima, mas, assim como na busca de custo uniforme, a memorização aumenta a eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c80841f-0f37-49c9-9819-4f54733c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos representar as transições na busca do caminho pela seguinte estrutura de dados\n",
    "@dataclass(order=True)\n",
    "class PrioritizedState:\n",
    "    priority: float\n",
    "    count: int # to break ties\n",
    "    state: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1860e8f-cccc-474f-8900-d5d1de315394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrioritizedState(priority=5, count=1, state=State(x=10, y=10))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [5,0,10]\n",
    "#heapq.heapify(L)\n",
    "L = []\n",
    "heapq.heappush(L, PrioritizedState(5, 1, State(10,10)))\n",
    "heapq.heappush(L, PrioritizedState(5, 2, State(1,10)))\n",
    "heapq.heappush(L, PrioritizedState(10, 0, State(10,10)))\n",
    "L\n",
    "\n",
    "heapq.heappop(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e2daf-a218-4ca9-bb4f-5db457091e32",
   "metadata": {},
   "source": [
    "### Heurística\n",
    "\n",
    "Precisamos informar uma heurística $h(s)$ obedecendo as seguintes propriedades:\n",
    "- $h(s) \\geq 0$\n",
    "- $h(m) = 0$ para o estado meta $m$\n",
    "- $h(s) \\leq C(s,m)$, com $C(s,m)$ indicando o menor custo do caminho de $s$ a $m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b21df659-e50e-4a88-9f4e-549e568a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(state: State, goal_state: State):\n",
    "    ''' Computes Manhattan distance from state to goal_state). '''\n",
    "    return abs(state.x-goal_state.x) + abs(state.y-goal_state.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3be6e2d2-3c5b-4198-b4af-f2342189e484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual a heurística para o estado inicial -- compare com solução ótima encontrada pela busca em largura (deve ser menor)\n",
    "heuristic(world.initial_state, goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dc0a483-6d97-40dd-b1dd-ae4397fbc2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca A* com memórização de fronteira\n",
    "def a_star_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = [PrioritizedState(heuristic(world.initial_state, goal_state), 0, world.initial_state)]\n",
    "    path_cost = {world.initial_state: 0.0}\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    counter = 0\n",
    "    while frontier:\n",
    "        pstate = heapq.heappop(frontier) # remove state with least priority f(n) = cost(n) + heuristic(n)\n",
    "        state = pstate.state\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            cost = path_cost[state] + world.cost(state, action)            \n",
    "            if (next_state not in path_cost) or (cost < path_cost[next_state]): # Avoids suboptimal paths\n",
    "                path_cost[next_state] = cost\n",
    "                f = cost + heuristic(next_state, goal_state)\n",
    "                counter += 1 # to break ties among states of equal priority\n",
    "                heapq.heappush(frontier, PrioritizedState(f, counter, next_state) )\n",
    "                backtrack[next_state] = state\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b35725f-e58d-4ab9-9f3b-a28750cc2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 34.0 visiting 163 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = a_star_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a6b92ab-2249-43e9-bb33-44b8eec4bd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26010023-d8ff-4f21-9406-722d62e35224",
   "metadata": {},
   "source": [
    "## Comparação\n",
    "\n",
    "Vamos comparar as buscas com relação à qualidade da solução encontrada (custo) e a eficiência (número de estados visitados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df566f4b-352f-4c7f-82c9-06c6ce489d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-star\n",
      "  - Average Cost: 30.25 \n",
      "  - Average Num. Iterations: 113.84\n",
      "BFS\n",
      "  - Average Cost: 30.25 \n",
      "  - Average Num. Iterations: 446.19\n",
      "DFS\n",
      "  - Average Cost: 184.82 \n",
      "  - Average Num. Iterations: 533.02\n"
     ]
    }
   ],
   "source": [
    "avg_cost_A = 0.0\n",
    "avg_cost_D = 0.0\n",
    "avg_it_A = 0\n",
    "avg_it_B = 0\n",
    "avg_it_D = 0\n",
    "\n",
    "N = 0\n",
    "for i in range(100):\n",
    "    myworld = World(50,10,0.1,False);\n",
    "    mygoal = None\n",
    "    for x in range(50):\n",
    "        for y in range(10):\n",
    "            if not myworld.grid[y,x]:\n",
    "                mygoal = State(x,y)\n",
    "                break\n",
    "        if mygoal is not None:\n",
    "            break\n",
    "    plan_A, cost_A, n_states_A = a_star_search(myworld, mygoal)\n",
    "    plan_B, cost_B, n_states_B = breadth_first_search2(myworld, mygoal)\n",
    "    plan_D, cost_D, n_states_D = depth_first_search(myworld, mygoal)\n",
    "    \n",
    "    if cost_A != cost_B: # This should never be true!\n",
    "        print(\"Oh, Oh! Something went wrong...\")\n",
    "        print(f\"A-star: {cost_A}  {n_states_A}\")\n",
    "        print(f\"BFS: {cost_B}  {n_states_B}\")    \n",
    "        break\n",
    "        \n",
    "    if cost_A < np.inf: # Discard unsolvable problems\n",
    "        N += 1\n",
    "        avg_cost_A += cost_A\n",
    "        avg_cost_D += cost_D\n",
    "        avg_it_A += n_states_A\n",
    "        avg_it_B += n_states_B\n",
    "        avg_it_D += n_states_D\n",
    "\n",
    "print(\"A-star\\n  - Average Cost:\", f\"{avg_cost_A/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_A/N:.2f}\")\n",
    "print(\"BFS\\n  - Average Cost:\", f\"{avg_cost_A/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_B/N:.2f}\")\n",
    "print(\"DFS\\n  - Average Cost:\", f\"{avg_cost_D/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_D/N:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9342c-dfb9-4bd7-a3cf-09610fc3f7d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Desenhe um mundo (a matriz da grade de ocupação) que maximize o desempenho da busca A* em comparação com as outras buscas. Reflita sobre as razões das ineficiências da busca não informada para pensar em uma grade de ocupação favorável para o A*. Depois, inverta o pensamento e desenhe uma matriz na qual A* desempenha de maneira similar à busca em largura e potencialmente pior que a busca em profundidade. Você espera encontrar situações assim em problemas de planejamento de rotas?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c762427-4b1a-441d-b3af-d78d19a65082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
